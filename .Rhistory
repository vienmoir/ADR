source('D:/DWNLDS/tdidf.r')
library(readr)
source('D:/DWNLDS/tdidf.r')
source('D:/DWNLDS/tdidf.r')
View(all)
View(all)
summary(docs)
docs
view(docs)
cl <- as.data.frame(docs)
docs$corpus
review_dtm_tfidf
review_dtm_tfidf <- DocumentTermMatrix(docs, control = list(weighting = weightTfIdf))
review_dtm_tfidf
inspect(review_dtm_tfidf[1,1:100])
inspect(docs)
inspect(docs[1])
inspect(docs[1]$content)
1 <- docs[1]
docs[1]
inspect(review_dtm_tfidf[1,1:100])
findFreqTerms(review_dtm_tfidf, lowfreq = 10)
findFreqTerms(review_dtm_tfidf[1], lowfreq = 10)
findFreqTerms(review_dtm_tfidf$dimnames, lowfreq = 10)
docs[1].content
docs.content
docs$content
docs$content[1]
inspect(docs$content[1])
install.packages(twitteR)
load.packages(twitteR)
library(tm)
library(ggplot2)
library(stringr)
library(Snowball)
library(SnowballC)
install.packages("SnowballC")
library(SnowballC)
install.packages("twitteR")
library(twitteR)
library(dplyr)
library(qdap)
install.packages("qdap")
library(qdap)
library(wordcloud)
source('D:/Uni/mas/twi/twi.R')
source('D:/Uni/mas/twi/twi.R')
source('D:/Uni/mas/twi/twi.R')
source('D:/Uni/mas/twi/twi.R')
api_key="	5KgNO1r0IcW4NaWcBbrZJm34H"
api_key="5KgNO1r0IcW4NaWcBbrZJm34H"
api_secret="r2qV4TCKBx81HAM4rJ6SlNmEHlsIPP0TjneBjRxir7998gqZnn"
access_token="942836002938413058-3LSXztLD5eMrfDAyCn0BdkUTEIOBL3g"
access_token_secret="	b5JE2L0pgFoPiBnApJRer6uQZsEO1SKG073VwfSDpdw1F"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(httr)
oauth_endpoints("twitter")
myapp <- oauth_app("twitter",
key = "5KgNO1r0IcW4NaWcBbrZJm34H",
secret = "r2qV4TCKBx81HAM4rJ6SlNmEHlsIPP0TjneBjRxir7998gqZnn"
)
twitter_token <- oauth1.0_token(oauth_endpoints("twitter"), myapp)
req <- GET("https://api.twitter.com/1.1/statuses/home_timeline.json",
config(token = twitter_token))
devtools::install_version("httr", version="0.6.0", repos="http://cran.us.r-project.org")
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(twitteR)
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
install.packages("devtools")
library(devtools)
devtools::install_version("httr", version="0.6.0", repos="http://cran.us.r-project.org")
install.packages("base64enc")
library(base64enc)
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(httr)
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(twitteR)
library(base64enc)
library(httr)
api_key="5uOaBWiXDmGbuZcwHAwjFlDQr"
api_secret="xEEVEXn62sfUsT3iZnl3fufJqCHMht2sdiZXd50WP83c0YPP5g"
access_token="942836002938413058-3LSXztLD5eMrfDAyCn0BdkUTEIOBL3g"
access_token="942836002938413058-3LSXztLD5eMrfDAyCn0BdkUTEIOBL3g"
access_token_secret="b5JE2L0pgFoPiBnApJRer6uQZsEO1SKG073VwfSDpdw1F"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
library(qdap)
library(ggplot2)
library(dplyr)
library(stringr)
library(tm)
library(SnowballC)
library(qdap)
library(wordcloud)
positive=scan('positive-words.txt',what='character',comment.char=';')
positive=scan('D:/Uni/mas/twi/positive-words.txt',what='character',comment.char=';')
negative=scan('D:/Uni/mas/twi/negative-words.txt',what='character',comment.char=';')
positive[20:30]
positive=c(positive,"cloud")
negative=negative[negative!="cloud"]
findfd = "GlobalWarming"
number = 5000
tweet=searchTwitter(findfd,number)
tweetT=lapply(tweet,function(t)t$getText())
head(tweetT,5)
tryTolower = function(x)
{
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error = function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
return(y)
}
clean=function(t){
t=gsub('[[:punct:]]','',t)
t=gsub('[[:cntrl:]]','',t)
t=gsub('\\d+','',t)
t=gsub('[[:digit:]]','',t)
t=gsub('@\\w+','',t)
t=gsub('http\\w+','',t)
t=gsub("^\\s+|\\s+$", "", t)
t=sapply(t,function(x) tryTolower(x))
t=str_split(t," ")
t=unlist(t)
return(t)
}
tweetclean=lapply(tweetT,function(x) clean(x))
head(tweetclean,5)
returnpscore=function(tweet) {
pos.match=match(tweet,positive)
pos.match=!is.na(pos.match)
pos.score=sum(pos.match)
return(pos.score)
}
positive.score=lapply(tweetclean,function(x) returnpscore(x))
pcount=0
for (i in 1:length(positive.score)) {
pcount=pcount+positive.score[[i]]
}
pcount
poswords=function(tweets){
pmatch=match(t,positive)
posw=positive[pmatch]
posw=posw[!is.na(posw)]
return(posw)
}
function (x, ...)
pdatamart=data.frame(words)
for (t in tweetclean) {
pdatamart=c(poswords(t),pdatamart)
}
head(pdatamart,10)
pdatamart=data.frame(words)
for (t in tweetclean) {
pdatamart=c(poswords(t),pdatamart)
}
head(pdatamart,10)
dpwords=data.frame(table(pwords))
dpwords=data.frame(table(poswords))
dpwords=data.frame(table(pdatamart))
pwords = unlist(pdatamart)
dpwords=data.frame(table(pwords))
pwords <- unlist(pdatamart)
dpwords=data.frame(table(pwords))
pwords <- as.vector(pdatamart)
dpwords=data.frame(table(pwords))
table(pwords)
pwords = unlist (pdatamart)
pwords = unlist(pdatamart)
for (t in tweetclean) {
pdatamart=c(poswords(t),pdatamart)
}
head(pdatamart,10)
pwords = unlist(pdatamart)
dpwords=data.frame(table(pwords))
pwords = list(pwords)
pwords = unlist(pwords)
dpwords=data.frame(table(pwords))
table(pwords)
dpwords=data.frame(pwords)
df <- data.frame(matrix(unlist(pwords)))
summary(df)
matrix(pwords)
dpwords=data.frame(table(pwords))
pwords < - unlist (pdatamart)
dpwords < - data.frame (table (pwords))
dpwords=data.frame(table(pwords))
dpwords <- data.frame (table (pwords))
is.list(pdatamart)
is.list(pwords)
unlist(pwords)
is.list(pwords)
unlist(pwords, use.names=FALSE)
is.list(pwords)
dpwords <- data.frame (table (pwords))
pwords <- unlist (pdatamart)
dpwords <- data.frame (table (pwords))
dpwords=data.frame(table(pwords))
pwords <- as.vecotr(pdatamart)
pwords <- as.vector(pdatamart)
dpwords <- data.frame (table (pwords))
dpwords=data.frame(table(pwords))
pwords <- as.factor(pdatamart)
pwords <- unlist(pdatamart, recursive = TRUE, use.names = TRUE)
dpwords <- data.frame (table (pwords))
pwords <- unlist(pdatamart, recursive = FALSE, use.names = FALSE)
dpwords <- data.frame (table (pwords))
pwords <- unlist(pdatamart)
is.list(pwords)
is.vector(pwords)
pwords <- table(pdatamart)
pwords <- matrix(pdatamart)
dpwords <- data.frame (table (pwords))
pwords <- data.frame(matrix(pdatamart))
dpwords <- data.frame (table (pwords))
dpwords <- data.frame(matrix(pdatamart))
dpwords=dpwords%>%
#nwords < - unlist (ndatamart)
dpwords <- data.frame (table (pwords))
library(ggplot2)
library(qdap)
library(dplyr)
library(stringr)
library(tm)
library(SnowballC)
library(wordcloud)
dpwords <- data.frame (table (pwords))
pwords <- unlist(pdatamart)
dpwords <- data.frame (table (pwords))
tweetscorpus=Corpus(VectorSource(tweetclean))
tweetscorpus=tm_map(tweetscorpus,removeWords,stopwords("english"))
stopwords("english")[30:50]
wordcloud(tweetscorpus,scale=c(5,0.5),random.order = TRUE,
rot.per = 0.20,use.r.layout = FALSE,colors = brewer.pal(6,"Dark2"),
max.words = 100)
dtm=DocumentTermMatrix(tweetscorpus)
dtms=removeSparseTerms(dtm,.99)
freq=sort(colSums(as.matrix(dtm)),decreasing=TRUE)
findFreqTerms(dtm,lowfreq=100)
wf=data.frame(word=names(freq),freq=freq)
wfh=wf%>%
filter(freq>=75,!word==tolower(findfd))
ggplot(wfh,aes(word,freq))+geom_bar(stat="identity",fill='lightblue')+theme_bw()+
theme(axis.text.x=element_text(angle=45,hjust=1))+
geom_text(aes(word,freq,label=freq),size=4)+labs(x="High Frequency Words ",
y="Number of Occurences",
title=paste("High Frequency Words and Occurence in \n '",findfd,"' twitter feeds, n =",number))+
geom_text(aes(1,max(freq)-100,label=paste("# Positive Words:",pcount,"\n","# Negative Words:",ncount,"\n",result(ncount,pcount))),size=5, hjust=0)
returnnscore
returnnscore=function(tweet) {
n.match=match(tweet,negative)
n.match=!is.na(n.match)
n.score=sum(n.match)
return(n.score)
}
negative.score=lapply(tweetclean,function(x) returnnscore(x))
ncount=0
for (i in 1:length(negative.score)) {
ncount=ncount+negative.score[[i]]
}
ncount
nwords=function(tweets){
nmatch=match(t,negative)
nw=positive[nmatch]
nw=nw[!is.na(nw)]
return(nw)
}
for (t in tweetclean) {
ndatamart=c(nwords(t),ndatamart)
}
words=NULL
ndatamart=data.frame(words)
for (t in tweetclean) {
ndatamart=c(nwords(t),ndatamart)
}
head(ndatamart,10)
ggplot(wfh,aes(word,freq))+geom_bar(stat="identity",fill='lightblue')+theme_bw()+
theme(axis.text.x=element_text(angle=45,hjust=1))+
geom_text(aes(word,freq,label=freq),size=4)+labs(x="High Frequency Words ",
y="Number of Occurences",
title=paste("High Frequency Words and Occurence in \n '",findfd,"' twitter feeds, n =",number))+
geom_text(aes(1,max(freq)-100,label=paste("# Positive Words:",pcount,"\n","# Negative Words:",ncount,"\n",result(ncount,pcount))),size=5, hjust=0)
library(twitteR)
library(qdap)
library(stringr)
library(tm)
library(SnowballC)
ggplot(wfh,aes(word,freq))+geom_bar(stat="identity",fill='lightblue')+theme_bw()+
theme(axis.text.x=element_text(angle=45,hjust=1))+
geom_text(aes(word,freq,label=freq),size=4)+labs(x="High Frequency Words ",
y="Number of Occurences",
title=paste("High Frequency Words and Occurence in \n '",findfd,"' twitter feeds, n =",number))+
geom_text(aes(1,max(freq)-100,label=paste("# Positive Words:",pcount,"\n","# Negative Words:",ncount,"\n",result(ncount,pcount))),size=5, hjust=0)
ggplot(wfh,aes(word,freq))+geom_bar(stat="identity",fill='lightblue')+theme_bw()+
theme(axis.text.x=element_text(angle=45,hjust=1))+
geom_text(aes(word,freq,label=freq),size=4)+labs(x="High Frequency Words ",
y="Number of Occurences",
title=paste("High Frequency Words and Occurence in \n '",findfd,"' twitter feeds, n =",number))+
geom_text(aes(1,max(freq)-100,label=paste("# Positive Words:",pcount,"\n","# Negative Words:",ncount)),size=5, hjust=0)
